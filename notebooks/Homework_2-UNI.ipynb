{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "### Due: Thurs Nov. 12 @ 11:59pm ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and hyperparameter tuning in both a regression and classification setting.\n",
    "\n",
    "We will be working with a small set of home sales data from as we might see on a real-estate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the comments below and fill in the blanks (\\_\\_\\_\\_) to complete.\n",
    "\n",
    "Please 'Restart and Run All' prior to submission.\n",
    "\n",
    "Out of 45 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts) Set up our environment with common libraries and plotting.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy as np, pandas as pd, matplotlib.pylab as plt and seaborn as sns\n",
    "____\n",
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# Set the seaborn style to 'darkgrid'\n",
    "____\n",
    "\n",
    "# Execute the matplotlib magic function to display plots inline\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1 we will try to predict a real value home sale price using several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (4pts) Load and prepare our data.\n",
    "\n",
    "# Read in the csv file house_sales_subset.csv using default parameter settings\n",
    "df = ____\n",
    "\n",
    "# Create a dataframe X which contains the columns:\n",
    "#    'SqFtTotLiving_x1000', 'SqFtLot_x1000', 'SqFtDriveway_x1000', 'Bathrooms', 'Bedrooms'\n",
    "X = ____\n",
    "\n",
    "# Create a series y_r which contains only the last column AdjSalePrice_x100000\n",
    "#    Note: the '_r' here is denote the different targets for regression and classification\n",
    "y_r = ____\n",
    "\n",
    "# Confirm that all features of X are similar in scale by displaying the output of describe()\n",
    "____\n",
    "\n",
    "# Use sns.histplot() to plot y_r to get a sense of the distribution of the target\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. (3pts) Create a held-aside set\n",
    "\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "____\n",
    "\n",
    "# Split X and y_r into 80% train and 20% test using train_test_split \n",
    "#   Use random_state=42 for grading consistency\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = ____\n",
    "\n",
    "# Print out the the length of y_test_r divided by the length y_r to confirm our test set size.\n",
    "print('proportion of data in test set: {:0.2f}'.format(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Baseline Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (3pts) Create a Dummy Regressor and confirm the expected performance on the training set.\n",
    "\n",
    "# Import the DummyRegressor model from sklearn \n",
    "____\n",
    "\n",
    "# Instantiate a dummy model using strategy=\"mean\" \n",
    "dummy_r = ____\n",
    "\n",
    "# Train the dummy model on the training set created above\n",
    "____\n",
    "\n",
    "# Calculate and print the training set R2 score of the dummy model.\n",
    "dummy_r_training_r2 = ____\n",
    "\n",
    "print('dummy training set R2: {:.2f}'.format(dummy_r_training_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Linear Regression and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (4pts) Import the Linear Regression model and fit on the training set.\n",
    "\n",
    "# Import the LinearRegression model from sklearn\n",
    "____\n",
    "\n",
    "# Instantiate a LinearRegression model with default arguments and fit on the training set\n",
    "lr = ____\n",
    "\n",
    "# Calculate and print the training set R2 of the LinearRegression model\n",
    "lr_training_r2 = ____\n",
    "\n",
    "print('lr training set R2: {:.2f}'.format(lr_training_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (2pts) Use 5-fold Cross Validation to measure variation of Liner Regression R2 performance.\n",
    "\n",
    "# Import cross_val_score from sklearn.\n",
    "____\n",
    "\n",
    "# Generate 5-fold cross-validation R2 scores for a LinearRegression model on the training set.\n",
    "scores = ____\n",
    "\n",
    "# Print out the R2 found by cross_val_score\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (2pts) Calculate mean cv R2 score +- 2 standard deviations for the Linear Regression model.\n",
    "\n",
    "# Calculate the mean cross validation score using the scores created above\n",
    "lr_r_cvr2_mean = ____\n",
    "\n",
    "# Calculate 2 standard deviations of the cross validation scores\n",
    "lr_r_cvr2_2std = ____\n",
    "\n",
    "# Print out the mean R2 and 2 standard variations for the LinearRegression model\n",
    "print('lr mean cv r2: {:.2f} +- {:.2f}'.format(lr_r_cvr2_mean,lr_r_cvr2_2std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. (2pts) Evaluate performance of our trained DummyRegressor and LinearRegression model on the test set\n",
    "\n",
    "# Calculate R2 on the test set using the trained models\n",
    "dummy_r_test_r2 = ____\n",
    "\n",
    "lr_test_r2 = ____\n",
    "\n",
    "print('dummy test R2 : {: .2f}'.format(dummy_r_test_r2))\n",
    "print('   lr test R2 : {: .2f}'.format(lr_test_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build several models to classify low vs. high adjusted sales price and practice creating validation curves and performing grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a binary target for classification by thresholding at the mean of our AdjSalePrice\n",
    "\n",
    "# The classes are:\n",
    "#    Low AdjSalePrice   = 0\n",
    "#    High AdjSalePrice = 1\n",
    "\n",
    "y_c = (df.AdjSalePrice_x100000 > df.AdjSalePrice_x100000.mean()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Create a Held-Aside Aet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (3pts) Create a training and test/held-aside set\n",
    "\n",
    "# Split into 80% train and 20% test using train_test_split with random_state=42\n",
    "#    Use the new y_c target and the same X we used for regression\n",
    "#    Also, use y_c to stratify the data so that the class proportions are the same in train and test\n",
    "#    Save the result into the variables X_train_c, X_test_c, y_train_c, y_test_c\n",
    "#    \n",
    "____\n",
    "\n",
    "# Print out the proportion of Low values (label of 0) in y_c\n",
    "____\n",
    "\n",
    "# Check to make sure that train and test have the same balance of classes.\n",
    "# Assert that the absolute difference between train and test in proportion of Low values is smaller than .01\n",
    "# Note that there may be a slight difference between train and test due to the different number of samples.\n",
    "assert ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. (2pts)  Create a Dummy Classifier and confirm the expected performance on the training set.\n",
    "\n",
    "# Import the DummyClassifier class\n",
    "____\n",
    "\n",
    "# Instantiate and fit a DummyClassifier on the training set\n",
    "#   Set the strategy argument to \"most_frequent\"\n",
    "dummy_c = ____\n",
    "\n",
    "# Print the trained DummyClassifier accuracy on the training set.\n",
    "# It should match the value we saw above.\n",
    "print('dummy training set accuracy: {:.3f}'.format(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3 RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. (4pts) Import, train and calculate 5-fold cv accuracy for a RandomForest model on the training set\n",
    "\n",
    "# Import the RandomForestClassifier model from sklearn\n",
    "____\n",
    "\n",
    "# Get 5 fold cross-validation training set accuracy scores for \n",
    "#   a RandomForestClassifier with 100 trees and max_depth=None (the default settings)\n",
    "#   To speed up training also set n_jobs=-1 in the cross_val_score call (to use all available cores)\n",
    "rfc_cvscores = ____\n",
    "\n",
    "# Calculate mean cv accuracy\n",
    "rfc_cvacc_mean = ____\n",
    "\n",
    "# Calculate 2 standard deviations for the cv scores\n",
    "rfc_cvacc_2std = ____\n",
    "\n",
    "print('rfc mean cv accuracy: {:.3f} +- {:.2f}'.format(rfc_cvacc_mean,rfc_cvacc_2std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 RandomForests and Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. (5pts) Generate a validation curve over different tree depths in a Random Forest\n",
    "\n",
    "# Import the validation_curve function from sklearn.model_selection\n",
    "____\n",
    "\n",
    "# In the RandomForestClassifier model, the depth of trees is set via max_depth\n",
    "# Here we'll try the depths 3,5,10,20,30\n",
    "depths = [3,5,10,20,30]\n",
    "\n",
    "# Generate the train_scores and test_scores for max_depth at these different depths using validation_curve\n",
    "#   Use RandomForestClassifier with default arguments except n_jobs=-1\n",
    "#   Use our training set X_train_c, y_train_c\n",
    "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
    "#   Use accuracy as the scoring metric\n",
    "train_scores,test_scores = ____\n",
    "\n",
    "# train_scores and test_scores contain a matrix of values\n",
    "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
    "#   Take the mean across folds (columns) and store in mean_train_scores and mean_test_scores\n",
    "mean_train_scores = ____\n",
    "mean_test_scores = ____\n",
    "\n",
    "# There should be five numbers in each list, each value between 0 and 1\n",
    "print(mean_train_scores)\n",
    "print(mean_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. (4pts) Plot the validation curve\n",
    "\n",
    "# Plot mean_train_scores and mean_test_scores on the same plot\n",
    "#    use either ax.plot() or plt.plot()\n",
    "#    use \"depths\" for the x values\n",
    "#    add a label to each line ('train' and 'test') \n",
    "#    add a legend\n",
    "#    label the x-axis as \"depth\" and the y-axis as \"mean accuracy\"\n",
    "# Note: use as many lines as necessary\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 RandomForests and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. (4pts) Perform 5-fold cross validated grid search over the number of trees and tree depth.\n",
    "\n",
    "# Import GridSearchCV\n",
    "____\n",
    "\n",
    "# Create the grid of parameters to test\n",
    "#   The parameter settings to try are 'n_estimators':[10,50,100,200], 'max_depth':[3,5,10,20,30]\n",
    "params = ____\n",
    "\n",
    "# Instantiate and fit GridSearchCV on the classification training set\n",
    "#   using 3-folds (for speed), the RandomForestClassifier and default scoring (accuracy).\n",
    "#   Make sure refit=True (default) so the model is retrained on the entire training set.\n",
    "#   Set n_jobs=-1 to use all cores.\n",
    "gscv_rf = ____\n",
    "\n",
    "# Print out the best the best hyperparameter setting found and the mean accuracy they produced (best_score_)\n",
    "print('rf best hyperparams      : {}'.format(____))\n",
    "print('rf best mean cv accuracy : {:.3f}'.format(____))\n",
    "\n",
    "# Note that you may get different answers on different runs due to \n",
    "#   the randomness within the Random Forest algorithms as well as\n",
    "#   the random cv splits used at each grid point\n",
    "\n",
    "# (to think about, don't need to answer)\n",
    "#  Does this match what we might have guessed our max_depth should be from the validation plot above?\n",
    "#  Why might it not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. (1pts) Evaluate our trained RandomForest model on the test set\n",
    "\n",
    "# Calculate accuracy on the held aside test set using the trained random forest model in gscv_rf.\n",
    "#   Note that we don't need to retrain on the full X_train_c,y_train_c as we used refit=True\n",
    "test_acc = ____\n",
    "\n",
    "print('test acc : {:.3f}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-f20",
   "language": "python",
   "name": "eods-f20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
